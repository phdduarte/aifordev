{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dos modelos (Embeddings e LLM)\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", max_tokens=200)\n",
    "\n",
    "# Carregar o PDF\n",
    "pdf_link = \"example2.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_link, extract_images=False)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# Separar em Chunks (Pedaços de documento)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000,  # Define o tamanho máximo de cada chunk em 4000 caracteres\n",
    "    chunk_overlap=20,  # Define uma sobreposição de 20 caracteres entre os chunks consecutivos\n",
    "    length_function=len,  # Usa a função len para calcular o tamanho dos chunks com base no número de caracteres\n",
    "    add_start_index=True  # Adiciona o índice de início em cada chunk para rastrear a posição original no documento\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvar no Vector DB - Chroma\n",
    "\n",
    "db = Chroma.from_documents(chunks, embedding=embeddings_model, persist_directory=\"new_index\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar DB\n",
    "vectordb = Chroma(persist_directory=\"new_index\", embedding_function=embeddings_model)\n",
    "\n",
    "#Load Retriever\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "#Construção da cadeia de prompt para chamada do LLM\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    context = retriever.get_relevant_documents(question)\n",
    "    answer = (chain({\"input_documents\": context, \"question\": question}, return_only_outputs=True))['output_text']\n",
    "    return answer, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Eu não sei exatamente qual solução de RAG você está se referindo. No entanto, RAG geralmente significa \"Retrieval-Augmented Generation\", uma técnica usada em processamento de linguagem natural que combina recuperação de informações com geração de texto. Se precisar de mais informações específicas ou um exemplo de implementação, recomendo consultar materiais especializados ou recursos relacionados.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"User: \")\n",
    "answer, context = ask(user_question)\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  page_content='Rocketseat\n",
      "Todos os direitos reservados#BoostingPeople\n",
      "rocketseat.com.br\n",
      "Arquitetura simples \n",
      "de RAG' metadata={'page': 34, 'source': 'example.pdf', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Context: \", context[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
